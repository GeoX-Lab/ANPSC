{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a single network for 3 MNIST tasks sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload edited modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython import display\n",
    "# import class Model\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist imshow convenience function\n",
    "# input is a 1D array of length 784\n",
    "def mnist_imshow(img):\n",
    "    plt.imshow(img.reshape([28,28]), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# return a new mnist dataset w/ pixels randomly permuted\n",
    "def permute(mnist):\n",
    "    perm_inds = list(range(mnist.train.images.shape[1]))\n",
    "    np.random.shuffle(perm_inds)\n",
    "    mnist2 = deepcopy(mnist)\n",
    "    sets = [\"train\", \"validation\", \"test\"]\n",
    "    for set_name in sets:\n",
    "        this_set = getattr(mnist2, set_name) # shallow copy\n",
    "        this_set._images = np.transpose(np.array([this_set.images[:,c] for c in perm_inds]))\n",
    "    return mnist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification accuracy plotting\n",
    "def plot_test_acc(plot_handles):\n",
    "    plt.legend(handles=plot_handles, loc=\"center right\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.ylim(0,1)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "# train/compare vanilla sgd and ewc\n",
    "def train_task1(model, num_iter, disp_freq, trainset, testsets, x,y1,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss1()\n",
    "        else:\n",
    "            model.update_MAS_loss1(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:                \n",
    "                for task in range(len(testsets)):\n",
    "                    feed_dict={x: testsets[task].test.images, y1: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy1.eval(feed_dict=feed_dict)                   \n",
    "            model.train_step1.run(feed_dict={x: batch[0], y1: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "\n",
    "def train_task2(model, num_iter, disp_freq, trainset, testsets, x,y2,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss2()\n",
    "        else:\n",
    "            model.update_MAS_loss2(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:                \n",
    "                for task in range(len(testsets)):\n",
    "                    feed_dict={x: testsets[task].test.images, y2: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy2.eval(feed_dict=feed_dict)                    \n",
    "            model.train_step2.run(feed_dict={x: batch[0], y2: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task3(model, num_iter, disp_freq, trainset, testsets, x,y3,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss3()\n",
    "        else:\n",
    "            model.update_MAS_loss3(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:                \n",
    "                for task in range(len(testsets)):                    \n",
    "                    feed_dict={x: testsets[task].test.images, y3: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy3.eval(feed_dict=feed_dict)                    \n",
    "            model.train_step3.run(feed_dict={x: batch[0], y3: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task4(model, num_iter, disp_freq, trainset, testsets, x,y4,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss4()\n",
    "        else:\n",
    "            model.update_MAS_loss4(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:              \n",
    "                for task in range(len(testsets)):\n",
    "                    feed_dict={x: testsets[task].test.images, y4: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy4.eval(feed_dict=feed_dict)                   \n",
    "            model.train_step4.run(feed_dict={x: batch[0], y4: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task5(model, num_iter, disp_freq, trainset, testsets, x,y5,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss5()\n",
    "        else:\n",
    "            model.update_MAS_loss5(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:               \n",
    "                for task in range(len(testsets)):\n",
    "                    \n",
    "                    feed_dict={x: testsets[task].test.images, y5: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy5.eval(feed_dict=feed_dict)                  \n",
    "                    \n",
    "            model.train_step5.run(feed_dict={x: batch[0], y5: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task6(model, num_iter, disp_freq, trainset, testsets, x,y6,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss6()\n",
    "        else:\n",
    "            model.update_MAS_loss6(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:                \n",
    "                for task in range(len(testsets)):\n",
    "                   \n",
    "                    feed_dict={x: testsets[task].test.images, y6: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy6.eval(feed_dict=feed_dict)\n",
    "                 \n",
    "            model.train_step6.run(feed_dict={x: batch[0], y6: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task7(model, num_iter, disp_freq, trainset, testsets, x,y7,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss7()\n",
    "        else:\n",
    "            model.update_MAS_loss7(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:\n",
    "                \n",
    "                for task in range(len(testsets)):                   \n",
    "                    feed_dict={x: testsets[task].test.images, y7: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy7.eval(feed_dict=feed_dict)\n",
    "                  \n",
    "            model.train_step7.run(feed_dict={x: batch[0], y7: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task8(model, num_iter, disp_freq, trainset, testsets, x,y8,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss8()\n",
    "        else:\n",
    "            model.update_MAS_loss8(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:              \n",
    "                for task in range(len(testsets)):\n",
    "                   \n",
    "                    feed_dict={x: testsets[task].test.images, y8: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy8.eval(feed_dict=feed_dict)\n",
    "                 \n",
    "            model.train_step8.run(feed_dict={x: batch[0], y8: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task9(model, num_iter, disp_freq, trainset, testsets, x,y9,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss9()\n",
    "        else:\n",
    "            model.update_MAS_loss9(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:\n",
    "               \n",
    "                for task in range(len(testsets)):\n",
    "                   \n",
    "                    feed_dict={x: testsets[task].test.images, y9: testsets[task].test.labels,keep_prob:1.0}\n",
    "                    test_accs[task][iter//disp_freq] = model.accuracy9.eval(feed_dict=feed_dict)\n",
    "                        \n",
    "                   \n",
    "            model.train_step9.run(feed_dict={x: batch[0], y9: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs\n",
    "\n",
    "def train_task10(model, num_iter, disp_freq, trainset, testsets, x,y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,keep_prob,lams):    \n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss10()\n",
    "        else:\n",
    "            model.update_MAS_loss10(lams[l])\n",
    "        # initialize test accuracy array for each task   \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter//disp_freq))\n",
    "        # train on current task\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(256)            \n",
    "            if iter % disp_freq == 0:\n",
    "                plt.subplot(1, len(lams), l+1)\n",
    "                plots = []\n",
    "                colors = ['r', 'b', 'g','y','k','#FAEBD7', '#7FFFD4', '#8A2BE2', '#A52A2A', '#DEB887']\n",
    "                for task in range(len(testsets)):\n",
    "                    if task==0:\n",
    "                        feed_dict={x: testsets[task].test.images, y1: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy1.eval(feed_dict=feed_dict)\n",
    "                    elif task==1:\n",
    "                        feed_dict={x: testsets[task].test.images, y2: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy2.eval(feed_dict=feed_dict)\n",
    "                    elif task==2:\n",
    "                        feed_dict={x: testsets[task].test.images, y3: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy3.eval(feed_dict=feed_dict)      \n",
    "                    elif task==3:\n",
    "                        feed_dict={x: testsets[task].test.images, y4: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy4.eval(feed_dict=feed_dict)\n",
    "                    elif task==4:\n",
    "                        feed_dict={x: testsets[task].test.images, y5: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy5.eval(feed_dict=feed_dict)\n",
    "                    elif task==5:\n",
    "                        feed_dict={x: testsets[task].test.images, y6: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy6.eval(feed_dict=feed_dict)\n",
    "                    elif task==6:\n",
    "                        feed_dict={x: testsets[task].test.images, y7: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy7.eval(feed_dict=feed_dict)\n",
    "                    elif task==7:\n",
    "                        feed_dict={x: testsets[task].test.images, y8: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy8.eval(feed_dict=feed_dict)\n",
    "                    elif task==8:\n",
    "                        feed_dict={x: testsets[task].test.images, y9: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy9.eval(feed_dict=feed_dict)\n",
    "                    else:\n",
    "                        feed_dict={x: testsets[task].test.images, y10: testsets[task].test.labels,keep_prob:1.0}\n",
    "                        test_accs[task][iter//disp_freq] = model.accuracy10.eval(feed_dict=feed_dict)\n",
    "                        \n",
    "                    c = chr(ord('A') + task)\n",
    "                    plot_h, = plt.plot(range(1,iter+2,disp_freq), test_accs[task][:iter//disp_freq+1], colors[task], label=\"task \" + c)\n",
    "                    plots.append(plot_h)\n",
    "                plot_test_acc(plots)\n",
    "                if l == 0: \n",
    "                    plt.title(\"vanilla sgd\")\n",
    "                else:\n",
    "                    plt.title(\"MAS\")\n",
    "                plt.gcf().set_size_inches(len(lams)*5, 3.5)\n",
    "            model.train_step10.run(feed_dict={x: batch[0], y10: batch[1],keep_prob:0.5})\n",
    "            #print(\"训练精度：\",model.accuracy.eval(feed_dict={x: batch[0], y_: batch[1],keep_prob:0.5}))\n",
    "    return test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载mnist数据集\n",
    "mnist = input_data.read_data_sets('data/mnist', one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "# define input and target placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y1 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y2 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y3 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y4 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y5 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y6 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y7 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y8 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y9 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "y10 = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "# instantiate new model\n",
    "model = Model(x,y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,keep_prob) # simple 2-layer network\n",
    "# initialize variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "mnist1 = permute(mnist)\n",
    "mnist2 = permute(mnist)\n",
    "mnist3 = permute(mnist)\n",
    "mnist4 = permute(mnist)\n",
    "mnist5 = permute(mnist)\n",
    "mnist6 = permute(mnist)\n",
    "mnist7 = permute(mnist)\n",
    "mnist8 = permute(mnist)\n",
    "mnist9 = permute(mnist)\n",
    "mnist10 = permute(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train on task A, test on task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training 1st task\n",
    "acc1=train_task1(model, 10000, 200, mnist1, [mnist1], x,y1,keep_prob,lams=[0])\n",
    "print(\"1th task acc:\",acc1[0][-1])\n",
    "# Fisher information\n",
    "model.compute_omega1(sess, mnist1.train, batch_size=1000,keep_prob=1.0)\n",
    "model.save_omega()  # save recent task Fisher matrix\n",
    "# save current optimal weights\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train on task B, test on tasks A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2=train_task2(model, 10000, 200, mnist2, [mnist2], x,y2,keep_prob, lams=[0,0.1])\n",
    "print(\"2th task acc:\",acc2[0][-1])\n",
    "model.compute_omega2(sess, mnist2.train, batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()  # save recent task Fisher matrix\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train on task C, test on tasks A, B, and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3=train_task3(model, 10000, 200, mnist3, [mnist3], x,y3,keep_prob,lams=[0,0.1])\n",
    "print(\"3th task acc:\",acc3[0][-1])\n",
    "model.compute_omega3(sess, mnist3.train, batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train on task C, test on tasks A, B, C and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4=train_task4(model, 10000, 200, mnist4, [mnist4], x,y4,keep_prob,lams=[0,0.1])\n",
    "print(\"4th task acc:\",acc4[0][-1])\n",
    "model.compute_omega4(sess, mnist4.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc5=train_task5(model, 10000, 200, mnist5, [mnist5],x,y5,keep_prob,lams=[0,0.1])\n",
    "print(\"5th task acc:\",acc5[0][-1])\n",
    "model.compute_omega5(sess, mnist5.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc6=train_task6(model, 10000, 200, mnist6, [mnist6],x,y6,keep_prob,lams=[0,0.1])\n",
    "print(\"6th task acc:\",acc6[0][-1])\n",
    "model.compute_omega6(sess, mnist6.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc7=train_task7(model, 10000, 200, mnist7, [mnist7],x,y7,keep_prob,lams=[0,0.1])\n",
    "print(\"7th task acc:\",acc7[0][-1])\n",
    "model.compute_omega7(sess, mnist7.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc8=train_task8(model, 10000, 200, mnist8, [mnist8],x,y8,keep_prob,lams=[0,0.1])\n",
    "print(\"8th task acc:\",acc8[0][-1])\n",
    "model.compute_omega8(sess, mnist8.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc9=train_task9(model, 10000, 200, mnist9, [mnist9],x,y9,keep_prob,lams=[0,0.1])\n",
    "print(\"9th task acc:\",acc9[0][-1])\n",
    "model.compute_omega9(sess, mnist9.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc10=train_task10(model, 10000, 200, mnist10, [mnist1, mnist2, mnist3, mnist4,mnist5,mnist6,mnist7,mnist8,\n",
    "                                                mnist9,mnist10],x,y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,keep_prob,lams=[0,0.1])\n",
    "print(\"1th task acc:\",acc10[0][-1],\"2th task acc:\",acc10[1][-1],\n",
    "      \"3th task acc:\",acc10[2][-1],\"4th task acc:\",acc10[3][-1],\"5th task acc:\",acc10[4][-1],\"6th task acc:\",acc10[5][-1],\n",
    "      \"7th task acc:\",acc10[6][-1],\"8th task acc:\",acc10[7][-1],\"9th task acc:\",acc10[8][-1],\"10th task acc:\",acc10[9][-1])\n",
    "###性能度量：计算遗忘程度\n",
    "F9=(acc1[0][-1]-acc10[0][-1]+acc2[0][-1]-acc10[1][-1]+acc3[0][-1]-acc10[2][-1]+acc4[0][-1]-acc10[3][-1]+acc5[0][-1]-acc10[4][-1]\n",
    "    +acc6[0][-1]-acc10[5][-1]+acc7[0][-1]-acc10[6][-1]+acc8[0][-1]-acc10[7][-1]+acc9[0][-1]-acc10[8][-1])/9 #计算九个任务的平均遗忘程度\n",
    "print(\"九个任务的平均遗忘程度：\",F9)\n",
    "ACC10=(acc10[0][-1]+acc10[1][-1]+acc10[2][-1]+acc10[3][-1]+acc10[4][-1]+acc10[5][-1]+acc10[6][-1]+acc10[7][-1]\n",
    "      +acc10[8][-1]+acc10[9][-1])/10\n",
    "print(\"十个任务的ACC为：\",ACC10)\n",
    "model.compute_omega10(sess, mnist10.train,batch_size=1000,keep_prob=1.0)\n",
    "model.omega_accumulate()\n",
    "model.save_omega()\n",
    "model.star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
